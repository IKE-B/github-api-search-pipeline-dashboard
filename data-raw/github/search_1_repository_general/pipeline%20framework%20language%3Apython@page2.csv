name;full_name;description;fork;html_url
APF;alercebroker/APF;apf is a framework developed to create a dockerized pipeline to process an alert stream, that can be easily be deployed in a local machine or distributed using Kubernetes.;false;https://github.com/alercebroker/APF
RoboPyPipeline;we45/RoboPyPipeline;Robot Framework Python Pipeline example;false;https://github.com/we45/RoboPyPipeline
griptape-flow;griptape-ai/griptape-flow;Python framework for building LLM workflows and pipelines with memory, rules, and chain of thought reasoning.;false;https://github.com/griptape-ai/griptape-flow
moona;katunilya/moona;Fairly simple railroad-oriented ASGI framework powered by monads and pipelines;false;https://github.com/katunilya/moona
ParSeq;kklmn/ParSeq;Python software library for Parallel execution of Sequential data analysis.;false;https://github.com/kklmn/ParSeq
drf-pipeline-views;MrThearMan/drf-pipeline-views;Django REST framework views using the pipeline pattern;false;https://github.com/MrThearMan/drf-pipeline-views
open-vfx-framework;trinix1975/open-vfx-framework;Visual Effects Pipeline Framework;false;https://github.com/trinix1975/open-vfx-framework
auto-generated-pipeline-framework;jason-jz-zhu/auto-generated-pipeline-framework;;false;https://github.com/jason-jz-zhu/auto-generated-pipeline-framework
pipedown;brendanhasz/pipedown;A data science pipelining framework for Python :shushing_face:;false;https://github.com/brendanhasz/pipedown
robotframework-circlecilibrary;trustedshops-public/robotframework-circlecilibrary;A extension for the Robot Framework to run and manage CircleCI pipelines;false;https://github.com/trustedshops-public/robotframework-circlecilibrary
midas;bioinformatics-ua/midas;MIDAS is a multi-framework DataLoader that can be leverage to produce highly efficient data pipelines;false;https://github.com/bioinformatics-ua/midas
niceml;codecentric-oss/niceml;" niceML üç¶ is a Python-based MLOps framework designed to streamline the development and maintenance of machine learning projects, offering efficient and scalable pipelines using TensorFlow and Dagster.";false;https://github.com/codecentric-oss/niceml
pyngsild;Orange-OpenSource/pyngsild;Python framework that helps you write a pipeline for your Fiware dataflow. It will be an equivalent to pyngsi (NGSIv2) but dedicated to NGSI-LD.;false;https://github.com/Orange-OpenSource/pyngsild
async-pipelines;alexkeating/async-pipelines;data processing framework;false;https://github.com/alexkeating/async-pipelines
karton-asciimagic;CERT-Polska/karton-asciimagic;Various decoders for ascii-encoded executables for Karton framework;false;https://github.com/CERT-Polska/karton-asciimagic
dyda;numbersprotocol/dyda;Dynamic data pipeline framework;false;https://github.com/numbersprotocol/dyda
Pipeline.py;KOLANICH-libs/Pipeline.py;A framework to build pipelines;false;https://github.com/KOLANICH-libs/Pipeline.py
sdk-python;go-vela/sdk-python;Python SDK for Vela (Target's official Pipeline Automation Framework);false;https://github.com/go-vela/sdk-python
Simple-Distributed-Data-Pipeline;YLiao98/Simple-Distributed-Data-Pipeline;This project implements naive query processing operators and provides some data-provenance-tracking functions within the operators. The project also utilizes Ray distributed computing framework to improve scalability.;false;https://github.com/YLiao98/Simple-Distributed-Data-Pipeline
Knowledge-Distillation-Pipeline;sithu31296/Knowledge-Distillation-Pipeline;PyTorch Knowledge Distillation Framework;false;https://github.com/sithu31296/Knowledge-Distillation-Pipeline
Luigi-Pipeline;rampk/Luigi-Pipeline;Building a machine learning pipeline using Luigi framework. This project does not focus on modelling accuracy, ability to use a fancy model, or efficiency.  It is mainly about the mechanics of building a proper machine learning pipeline.;false;https://github.com/rampk/Luigi-Pipeline
karton-autoit-ripper;CERT-Polska/karton-autoit-ripper;AutoIt script ripper for Karton framework;false;https://github.com/CERT-Polska/karton-autoit-ripper
deba;pckhoi/deba;Environment-agnostic data pipeline framework;false;https://github.com/pckhoi/deba
data-pipeline-demo-1;AlexandreGarito/data-pipeline-demo-1;This project is a Python-coded and GCP-hosted micro-ETL data pipeline and interactive dashboard that displays API data using the Dash-Plotly web framework, updated daily using DevOps tools such as CI/CD, Docker, and Airflow.;false;https://github.com/AlexandreGarito/data-pipeline-demo-1
WTU;ag-sc/WTU;Web Table Understanding Framework than parses JSON Web Tables and provides pipeline for annotating/extracting triples;false;https://github.com/ag-sc/WTU
lambdaedge-serverless-cicd;nikosheng/lambdaedge-serverless-cicd;Based on serverless framework to build up a CICD pipeline for lambda edge development with preexisting CloudFront distribution;false;https://github.com/nikosheng/lambdaedge-serverless-cicd
MedAI-Framework;LexTran/MedAI-Framework;This repository provides an universal pipeline for medical image segmentation with the support of Pytorch & MONAI.;false;https://github.com/LexTran/MedAI-Framework
NLP_Pipeline;chaojieji/NLP_Pipeline;Construct generic framework for NLP missions, basing on various third-party libraries.;false;https://github.com/chaojieji/NLP_Pipeline
snowflet;bluefloyd00/snowflet;Snowflake pipeline, etl, data science framework;false;https://github.com/bluefloyd00/snowflet
event-pipeline;muxer-dev/event-pipeline;An implementation of an events state machine using AWS Step Functions and the Serverless framework.;false;https://github.com/muxer-dev/event-pipeline
DataPipelines;DragosManailoiu/DataPipelines;scripts to automate the ETL/ELT process using cloud and orchestration frameworks;false;https://github.com/DragosManailoiu/DataPipelines
Fast-Api-Vue;KenMwaura1/Fast-Api-Vue;Simple asynchronous API implemented with Fast-Api framework utilizing Postgres as a Database and SqlAlchemy as ORM . GiHub Actions as CI/CD Pipeline. Vue + Daisy UI for the frontend;false;https://github.com/KenMwaura1/Fast-Api-Vue
gurun;gabrielguarisa/gurun;Task automation framework;false;https://github.com/gabrielguarisa/gurun
MLDebugger;raonilourenco/MLDebugger;"Code for ""Debugging Machine Learning Pipelines"".  the Algorithms of MLDebugger are now part of BugDoc, a general pipeline debugger framework. This repository will keep the experiments for the DEEM paper,  please check BugDoc's repository for the latest developments.";false;https://github.com/raonilourenco/MLDebugger
data-science-modeling-framework;msarafzadeh/data-science-modeling-framework;Data Science frame work created to assist the modeling pipeline: from EDA, to model training, to best model selection, to threshold optimization, to model explainabilty.;false;https://github.com/msarafzadeh/data-science-modeling-framework
FaceDNR-public;systemcorp-ai/FaceDNR-public;Face Detection and Recognition pipeline built on top of OpenCV framework;false;https://github.com/systemcorp-ai/FaceDNR-public
lightning-streams;BayoAdejare/lightning-streams;Batch/stream ETL pipeline of NOAA GLM dataset, using Python frameworks: Dagster, PySpark and Parquet storage. ;false;https://github.com/BayoAdejare/lightning-streams
sql-azure-functions-adf-event-trigger;joe-plumb/sql-azure-functions-adf-event-trigger;Code example to demonstrate custom event triggered ADF pipelines driven from metadata frameworks in SQL;false;https://github.com/joe-plumb/sql-azure-functions-adf-event-trigger
End-to-end-ML-System-Benchmark;hpides/End-to-end-ML-System-Benchmark;A modular suite for benchmarking all stages of Machine Learning pipelines. To find bottlenecks in such pipelines and compare different ML tools, this framework can calculate and visualize several metrics in the data preparation, model training, model validation and inference stages.;false;https://github.com/hpides/End-to-end-ML-System-Benchmark
ICCP;HaroldBenoit/ICCP;ICCP or Integrated Comfort Controller Pipeline is a framework for research of reinforcement learning based controllers in the context of energy saving and thermal comfort in buildings.;false;https://github.com/HaroldBenoit/ICCP
pipes;vani-public/pipes;Infrastructure independent task execution framework based on logical task pipelines;false;https://github.com/vani-public/pipes
ETLite;elau1004/ETLite;A lightweight framework to host your ETL data-pipeline;false;https://github.com/elau1004/ETLite
wikipedia_data_pipeline;BermanDS/wikipedia_data_pipeline;Data pipeline with using as source - Streaming API from wikipedia.org. The further points in pipeline will be Kafka, Flink framework and PostgreSQL.;false;https://github.com/BermanDS/wikipedia_data_pipeline
nodework;martindur/nodework;node framework for pipelines, with file handling and processing;false;https://github.com/martindur/nodework
ToFu;0Miquel/ToFu;TorchFusion (ToFu) is a modular pytorch training pipeline.  It integrates the most well-known frameworks for machine learning like WandB, Hydra and Optuna.;false;https://github.com/0Miquel/ToFu
arpsas;JordyBottelier/arpsas;This repository contains the framework and experiments that were used for writing the thesis with the title: A Reconfigurable Pipeline for Semi-Automatic Schema Matching;false;https://github.com/JordyBottelier/arpsas
theflow;trducng/theflow;Pipeline development framework, easy to experiment and compare different pipelines, quick to deploy to workflow orchestration tools;false;https://github.com/trducng/theflow
spine;shaharluftig/spine;Spine: the backbone of your data pipeline.;false;https://github.com/shaharluftig/spine
lambda-restapi;gbourniq/lambda-restapi;Quickly develop and deploy serverless REST APIs with FastAPI, AWS Lambda, and AWS API Gateway. This includes a CI/CD pipeline with Travis and the AWS SAM Framework.;false;https://github.com/gbourniq/lambda-restapi
SCIP;ScalableCytometryImageProcessing/SCIP;Scalable Cytometry Image Processing (SCIP) is an open-source tool that implements an image processing pipeline on top of Dask, a distributed computing framework written in Python. SCIP performs projection, illumination correction, image segmentation and masking, and feature extraction.;false;https://github.com/ScalableCytometryImageProcessing/SCIP
phd_template;sbucaille/phd_template;Template to create training pipeline using PytorchLighning, Hydra and DVC frameworks;false;https://github.com/sbucaille/phd_template
betl;brianspurling/betl;A Kimball ETL (Extract, Transform, Load) framework for building robust data pipelines in Python;false;https://github.com/brianspurling/betl
ipipeline;novaenext/ipipeline;A micro framework to build and execute pipelines from different domains.;false;https://github.com/novaenext/ipipeline
astromlp;nunorc/astromlp;A framework for building deep learning models and pipelines for astrophysics applications.;false;https://github.com/nunorc/astromlp
fastapi-localtrack;mbari-org/fastapi-localtrack;Lightweight Machine Learning API for running video tracking pipelines powered by the FastAPI framework;false;https://github.com/mbari-org/fastapi-localtrack
treasure-data-digdag-graph;anilkulkarni87/treasure-data-digdag-graph;How to visualize digdag? digdag is an open source etl pipeline framework by Treasure-Data;false;https://github.com/anilkulkarni87/treasure-data-digdag-graph
lavactl;alfonsoros/lavactl;tool ment to help with the setup of CI pipelines using Linaro's LAVA testing framework;false;https://github.com/alfonsoros/lavactl
Deploying_Scalable_ML_Pipeline_in_Production;Minhvt34/Deploying_Scalable_ML_Pipeline_in_Production;This repo to develop a classification model by applying unit tests to monitor the model performance on various slices of the data. Then, deploying the model using FastAPI package and create API tests. Both the slice-validation and the API tests will be incorporated into a CI/CD framework using GitHub Actions. ;false;https://github.com/Minhvt34/Deploying_Scalable_ML_Pipeline_in_Production
CCAugmentation;pijuszczyk/CCAugmentation;Data preprocessing & augmentation framework, designed for working with crowd counting datasets, ML/DL framework-independent. Supports multitude of simple as well as advanced transformations, outputs and loaders, all of them to be combined using pipelines.;false;https://github.com/pijuszczyk/CCAugmentation
spydy;superjcd/spydy;Âü∫‰∫éPipelineÁöÑÁà¨Ëô´Ê°ÜÊû∂Ôºå Â∑•‰ΩúÊµÅÈùûÂ∏∏ÁÆÄÂçï„ÄÅÁõ¥ËßÇÔºå ËÄå‰∏îÊîØÊåÅÂºÇÊ≠•„ÄÇlight-weight high-level web-crawling framework;false;https://github.com/superjcd/spydy
vehicle-detection-system-in-python;Aklilu-Mandefro/vehicle-detection-system-in-python;Created vehicle detection pipeline with two approaches: (1) deep neural networks (YOLO framework) and (2) support vector machines ( OpenCV + HOG). ;false;https://github.com/Aklilu-Mandefro/vehicle-detection-system-in-python
SigmaParticle;dzyphr/SigmaParticle;framework for interacting with ergo blockchain based on ergpy to be used in cross chain pipeline extensions;false;https://github.com/dzyphr/SigmaParticle
Point-of-sale-Python-Django-CICD;santiagortiiz/Point-of-sale-Python-Django-CICD;Point of sales application developed in Django and REST framework with CI/CD pipelines with GitHub actions;false;https://github.com/santiagortiiz/Point-of-sale-Python-Django-CICD
laplace-gnn-recommendation;dream-faster/laplace-gnn-recommendation;‚õìÔ∏è laplace is an end-to-end ML framework to train and predict on neurally-enhanced graphs for recommendation.  The pipeline is designed for self-supervised edge prediction on heterogenous graphs.;false;https://github.com/dream-faster/laplace-gnn-recommendation
pachelm;sinonkt/pachelm;Pachelm [Pla - chelm] (Pachyderm + helm) helm style + laravel migration & seeds style framework to manage pipeline deployment as a package of migrations.;false;https://github.com/sinonkt/pachelm
lambda-functions-actions;rribeiro1/lambda-functions-actions;AWS Lambda function implemented with Serverless framework and CI pipeline using GitHub actions. It also integrates with CodeClimate for test coverage reports.;false;https://github.com/rribeiro1/lambda-functions-actions
happy-tasks;garrylachman/happy-tasks;"""Happy Tasks"" is an Python Framework for building tasks based batch processes. A network of pipelines, triggers, dependencies, workflow management, reporting & scheduling.";false;https://github.com/garrylachman/happy-tasks
FastApi-Signoz-App;KenMwaura1/FastApi-Signoz-App;Simple asynchronous API implemented with Fast-Api framework utilizing Postgres as a Database and SqlAlchemy as ORM . GitHub Actions as CI/CD Pipeline;false;https://github.com/KenMwaura1/FastApi-Signoz-App
mastering_mediapipe;bhav09/mastering_mediapipe;MediaPipe is a an open-source framework from Google for building multimodal (eg. video, audio, any time series data), cross platform (i.e Android, iOS, web, edge devices) applied ML pipelines. It is performance optimized with end-to-end on device inference in mind.;false;https://github.com/bhav09/mastering_mediapipe
machine-learning-hyperparameter-optimization-app;ishani-chakraborty/machine-learning-hyperparameter-optimization-app;Machine Learning App using the StreamLit web framework that aims to eliminate the barrier in understanding machine learning model building by streamlining the process thereby allowing non-technical users to harness the power of machine learning through data visualization and input customization;false;https://github.com/ishani-chakraborty/machine-learning-hyperparameter-optimization-app
api_project;koomani/api_project;Building a full API in Python using FastAPI along with HTTP requests tested by postman tool, Sql database connections, automation testing with pytest framework, and building  CI/CD pipelines;false;https://github.com/koomani/api_project
Clockwork;facebookresearch/Clockwork;Recurring batch data pipelines are a staple of the modern enterprisescale data warehouse. As a data warehouse scales to support more products and services, a growing number of interdependent pipelines running at various cadences can give rise to periodic resource bottlenecks for a cluster. This resource contention results in pipelines starting at unpredictable times each day and consequently variable landing times for the data artifacts they produce. The variability gets compounded by the dependency structure of the workload, and the resulting unpredictability can disrupt the project workstreams which consume this data. We present Clockwork, a delay-based global scheduling framework for data pipelines which improves landing time stability by spreading out tasks throughout the day. Whereas most scheduling algorithms optimize for makespan or average job completion times, Clockwork‚Äôs execution plan optimizes for stability in task completion times while also targeting predifined pipeline. Online experiments comparing this novel scheduling algorithm and a previously proposed greedy procrastinating heurstic show tasks complete almost an hour earlier on average, while exhibiting lower landing time variance and producing significantly less competition for resources in a target cluster.;false;https://github.com/facebookresearch/Clockwork
python-devops;Viha27/python-devops;A Devops pipeline is set of automated processes and tools that the development (Dev) and operations (Ops) teams implement to build, test, and deploy software faster and easier.  In this course you will complete DevOps pipeline generally consists of a set of tools which are normally broken down into the following categories:  Plan  Code  Integrate  Test  Release  Deploy  Operate  This learning path will cover:  Git is an open-source and distributed version control system.  Github is git repository hosting service used for code sharing, bug tracking, feature request and much more.    PyCharm is an integrated development environment (IDE) for python programing language.  Flask is a python web framework.  HTML is the standard markup language for Web pages.  CSS is a style sheet language use to style a HTML document.  SQLAlchemy is an open-source SQL toolkit and object-relational mapper which gives full power and flexibility of SQL.    Selenium is used to automate web browser interaction.  Pytest is unit testing framework that allows users to write test codes.    Ngrok allows to expose a web server running on your local machine to the internet.    Github Action enables you to include Continues Integration (CI) and continuous deployment (CD) capabilities and many other features directly in your repository.    Docker is an open source containerization platform enables developers to package applications into containers.  Docker Hub is a cloud-based repository for finding and sharing container images with your team.  Kubernetes is an open-source container orchestration for automating deployment, scaling, and management of containerized applications.  This course is one stop shop where you will learn web development, continuous integration, continuous deployment, containerization, writing neat and quality code, devops concepts and much more with python programing language.  What you‚Äôll learn Learn to build Continuous Integration Continuous Deployment pipeline Build CI CD tool to update docker image after any update Learn to create dockerfile Learn the fundamental concepts of Docker Learn the fundamental concepts of Kubernetes Learn to create Kubernetes YAML files Learn to deploy high availability, fault tolerance, scalable application Learn all the basic and advanced git commands Learn different types of branches like master, developer, feature, release and hotfix branch Learn fundamental concepts of Version Control System Learn to use Github actions for CI CD pipeline Learn to build python flask web application Learn to use SQL Alchemy Lean to create HTML pages using HTML, CSS and bootstrap Are there any course requirements or prerequisites? Git installed Docker installed Kubernetes installed Any IDE Github account Docker hub account Who this course is for: Anyone who wants to Enhance their skills in DevOps domain Developers and IT Pros Instructor User photo Pranjal Srivastava Docker | Kubernetes | AWS | Azure | ML | Linux | Python  I am an Instructor, Devops engineer, machine learning enthusiast, cloud expert and passionate developer.  I have authored 60+ courses with over 50,000+ students worldwide across 175+ countries on wide array of technologies like containerization, machine learning, Linux, programming languages and cloud computing platforms like Microsoft Azure, Amazon Web Service and IBM Cloud.;false;https://github.com/Viha27/python-devops
AI-Attention-assist-system-using-MediaPipe;Arwindhraj/AI-Attention-assist-system-using-MediaPipe;Utilizing MediaPipe, a cross-platform framework for creating computer vision pipelines, we created an attention support system. The system uses EAR and MAR to assess the driver's level of drowsiness. An alarm will sound to warn the driver if they are becoming sleepy.;false;https://github.com/Arwindhraj/AI-Attention-assist-system-using-MediaPipe
