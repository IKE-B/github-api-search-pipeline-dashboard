name;full_name;description;fork;html_url
opensearch-catalog;opensearch-project/opensearch-catalog;The OpenSearch Catalog is designed to make it easier for developers and community to contribute, search and install artifacts like plugins, visualization dashboards, ingestion to visualization content packs (data pipeline configurations, normalization, ingestion, dashboards).;false;https://github.com/opensearch-project/opensearch-catalog
coches-net-dashboard;franloza/coches-net-dashboard;Sample project that use Dagster, dbt, DuckDB and Dash to visualize car and motorcycle Spanish market;false;https://github.com/franloza/coches-net-dashboard
divvy-bikeshare-de-project;Fozan-Talat/divvy-bikeshare-de-project;An end-to-end data pipeline which extracts divvy bikeshare data from web loads it into data lake and datawarehouse transforms it using dbt and finally , a dashboard to visualize the data using looker studio, the pipeline is orchestrated using prefect;false;https://github.com/Fozan-Talat/divvy-bikeshare-de-project
ETL-Data-Pipelines-Data-Warehousing-Business-Intelligence-;akashmdubey/ETL-Data-Pipelines-Data-Warehousing-Business-Intelligence-;This project challenged us to process and integrate data coming in from a variety of sources - IMDb data, movie rating data from MovieLens, and The Numbers data. We utilized multiple features of the Talend and SQL server to optimize the complete ETL process    We then visualized the integrated data from our dimensional model in #Tableau and #PowerBI dashboards showcasing some core KPIs and metrics.    This project helped us understand the various challenges faced while building data integration pipelines and business intelligence applications. ;false;https://github.com/akashmdubey/ETL-Data-Pipelines-Data-Warehousing-Business-Intelligence-
LiveCryptocurrencyDashboard;edoardorealini/LiveCryptocurrencyDashboard;A full Big Data pipeline implemplement in Scala and Python for generating live predictions of crypos prices. Technologies: Python, Scala, Kafka, FB's Prophet, Cassandra and Plotly for final visualization. ;false;https://github.com/edoardorealini/LiveCryptocurrencyDashboard
Ecommerce-Analytics-Dashboard;Baci-Ak/Ecommerce-Analytics-Dashboard;An E-commerce Analytics Dashboard project showcasing data pipeline automation with Apache NiFi, data analysis with SQL and Python, and interactive data visualization using Tableau.;false;https://github.com/Baci-Ak/Ecommerce-Analytics-Dashboard
BeerReviewsDataPipeline;directdetour/BeerReviewsDataPipeline;The Beer Reviews Data Pipeline is a data engineering project that involves extracting, preprocessing, and storing beer review data from a Kaggle dataset in a Google Cloud Storage data lake. The data pipeline is built using Python, and Prefect, and includes a Metabase dashboard for data visualization.;false;https://github.com/directdetour/BeerReviewsDataPipeline
Data-Pipeline-of-NOAA-Storm-Events-and-Sevir-Data;keerti-26/Data-Pipeline-of-NOAA-Storm-Events-and-Sevir-Data;Implementing a data pipeline of SEVIR and Storm Events using Amazon Web Services S3 bucket for storage, Amazon Glue for ETL and Amazon Quicksight for Visualization and Dashboard creation. Implemented a data pipeline using different GCP components, Google Cloud Storage, Datalab, Apache Beam, Dataflow, Google Bigquery and Google Data Studio. Also created a pipeline using Snowflake tables by ingesting the data using Apache Airflow.;false;https://github.com/keerti-26/Data-Pipeline-of-NOAA-Storm-Events-and-Sevir-Data
IMDB_Database_Warehousing_and_Business_Intelligence;kpkaranpatil600/IMDB_Database_Warehousing_and_Business_Intelligence;Designed Multi Star schema with 10 Fact & 33 Dimension tables & developed Data Integration Pipeline by ETL workflow to load all tables (380M+ rows) from multiple sources such as CSV, MySQL, MSSQL & PostgreSQL by using Talend. Implemented Data Profiling, Error Handling, Load Statistics, Cleansing and Performance Tuning to address data quality gaps & maintained referential integrity using Alteryx & Talend. Executed SQL scripts & created interactive visualization dashboards on PowerBI & Tableau for analyzing the data to draw better insights on sales & customer segmentation;false;https://github.com/kpkaranpatil600/IMDB_Database_Warehousing_and_Business_Intelligence
Sales-Insight-Dashboard;rushabhgajjar/Sales-Insight-Dashboard;This dashboard is created using Power BI to provide sales insights. Various operations performed include connecting to a data source which is MySQL in this case, data cleaning-ETL in Power Query, manage relationship between tables, create measures using DAX and use them in visualizations, maintain data pipeline during changes/updates to data source, publish report to BI service, create mobile layout to access dashboard from mobile.;false;https://github.com/rushabhgajjar/Sales-Insight-Dashboard
Data-Warehouse-for-online-store;kingsleydata/Data-Warehouse-for-online-store;This project shows how I create a SQL data warehouse for an online store including how I establish the data pipeline, validate the data, run some analytics on the DATA to find important insights and finally create a visualization dashboard report in Tableau.;false;https://github.com/kingsleydata/Data-Warehouse-for-online-store
ELT_sensordata;Kibika/ELT_sensordata;The project uses PySpark, MySQL and dbt to create an ELT pipeline. It also uses redash to create a dashboard to visualize the analysis as more data streams in.;false;https://github.com/Kibika/ELT_sensordata
Data-Analytics-Training-in-Gurgaon-Data-Analytics-Course-in-Gurgaon;sana212/Data-Analytics-Training-in-Gurgaon-Data-Analytics-Course-in-Gurgaon;"Data analytics isn’t just about the future, it is being put to use at this very moment in all businesses. It forms an integral part of the company and the professionals are paid highly for their part. Here are reasons why joining data analytics training in Gurgaon is a viable option   After the completion of Data Analytics Course, you will be able to:   Understand Scala & Apache Spark implementation   Spark operations on Spark Shell   Spark Driver & its related Worker Nodes   Spark + Flume Integration   Setting up Data Pipeline using Apache Flume, Apache Kafka & Spark Streaming   Spark RDDs and Spark Streaming   Spark MLib : Creating Classifiers & Recommendations systems using MLib    Spark Core concepts: Creating of RDDs: Parrallel RDDs, MappedRDD, HadoopRDD, JdbcRDD.   Spark Architecture & Components   Spark SQL experience with CSV, XML & JSON   Reading data from different Spark sources   Spark SQL & Dataframes   Develop and Implement various Machine Learning Algorithms in daily practices & Live Environment   Building Recommendation systems and Classifiers   Perform various type of Analysis (Prediction & Regression)   Implement plotting & graphs using various Machine Learning Libraries   Import data from HDFS & Implement various Machine Learning Models   Building different Neural networks using NumPy and TensorFlow   Power BI Visualization   Power BI Components   Power BI Transformations   Dax functions   Data Exploration and Mapping   Designing Dashboards   Time Series, Aggregation & Filters      Placement   Gyansetu is providing complimentary placement service to all students. Gyansetu Placement Team consistently works on industry collaboration and associations which help our students to find their dream job right after the completion of training.      Why Choose us?   Gyansetu trainers are well known in Industry; who are highly qualified and currently working in top MNCs.   We provide interaction with faculty before the course starts.   Our experts help students in learning Technology from basics, even if you are not good at basic programming skills, don’t worry! We will help you.   Faculties will help you in preparing project reports & presentations.   Students will be provided Mentoring sessions by Experts.    ";false;https://github.com/sana212/Data-Analytics-Training-in-Gurgaon-Data-Analytics-Course-in-Gurgaon
